---
title: Real-Time Face Tracking
date: 2024-07-21 16:00:00 +0300
categories: [Tello Drone]
tags: [python, djitellopy, pygame]     # TAG names should always be lowercase
image: assets/img/tello/tello_drone_03.png
---

In this project, I share a real-time face tracking system using the DJI Tello drone. The setup utilizes Python and the `djitellopy` library to control the drone, while OpenCV is employed for face detection. Let’s dive into the implementation and the results!

## Project Overview

The goal of this project was to create a drone capable of following and tracking a face using its onboard camera. The drone is programmed to take off, maintain a stable altitude, and use computer vision to detect and follow a face within its camera’s view.

## Code Walkthrough

Here’s a breakdown of the code used to achieve face tracking:

```python
import time
import numpy as np
from djitellopy import Tello
import cv2

uav = Tello()
uav.connect()
print(f"Battery: {uav.get_battery()}%")

uav.streamon()
# uav.takeoff()
# uav.send_rc_control(0, 0, 25, 0)
# time.sleep(2.2)

w, h = 360, 240
fbRange = [6200, 6800]  # The face is within this range. Experimental info
pid = [0.4, 0, 0.4]
pError = 0


def findFace(img):
    faceCascade = cv2.CascadeClassifier("Resources/haarcascade_frontalface_default.xml")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    #    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = faceCascade.detectMultiScale(img, 1.2, 8)

    myFaceListC = []
    myFaceListArea = []

    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
        cx = x + w // 2
        cy = y + h // 2
        area = w * h
        cv2.circle(img, (cx, cy), 5, (0, 255, 0), cv2.FILLED)
        myFaceListC.append([cx, cy])
        myFaceListArea.append(area)
    if len(myFaceListArea) != 0:
        i = myFaceListArea.index(max(myFaceListArea))
        return img, [myFaceListC[i], myFaceListArea[i]]
    else:
        return img, [[0, 0], 0]


def trackFace(uav, info, w, pid, pError):
    area = info[1]
    x, y = info[0]
    fb = 0

    error = x - w // 2
    speed = pid[0] * error + pid[2] * (error - pError)
    speed = int(np.clip(speed, -100, 100))

    if area > fbRange[0] and area < fbRange[1]:
        fb = 0
    if area > fbRange[1]:
        fb = -20
    elif area < fbRange[0] and area != 0:
        fb = 20

    if x == 0:
        speed = 0
        error = 0

    # print(speed, fb)
    uav.send_rc_control(0, fb, 0, speed)
    return error


# cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
while True:
    # _, img = cap.read()
    img = uav.get_frame_read().frame
    img = cv2.resize(img, (w, h))
    img, info = findFace(img)
    pError = trackFace(uav, info, w, pid, pError)
    # print("Center", info[0], "Area", info[1])
    cv2.imshow("Output", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        uav.land()
        break

```

## Setting Up Haar Cascade for Face Detection

To use the face detection functionality, you need the Haar Cascade XML file. Follow these steps to download and set it up:

1. **Download the XML File**: You can download the `haarcascade_frontalface_default.xml` file from the OpenCV GitHub repository. Here is the direct link: [Haar Cascade XML File](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml).

2. **Save the File**: After downloading the XML file, create a folder named `Resources` in your project directory if it doesn't already exist.

3. **Place the File**: Move the downloaded `haarcascade_frontalface_default.xml` file into the `Resources` folder.

Your project directory should look something like this:

```
/your-project
    /Resources
        haarcascade_frontalface_default.xml
    your_script.py
```

### Key Components

1. **Drone Initialization**: The `Tello` object connects to the drone and starts video streaming.
2. **Face Detection**: Using OpenCV’s Haar Cascade Classifier, the script detects faces and determines their position and size.
3. **Face Tracking**: The drone adjusts its position based on the detected face, using a PID controller to correct its movements.
4. **Real-Time Display**: The live video feed with detected faces is displayed using OpenCV’s `imshow` function.

### Results

The face tracking works effectively in real-time, allowing the drone to follow the face within its camera's field of view. The PID controller ensures smooth adjustments and keeps the face centered in the frame. The system also maintains a suitable distance from the face based on its size.
